{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Omnidirectional Transfer for Quasilinear Lifelong Learning\n",
    "\n",
    "[![Paper](https://img.shields.io/badge/Paper-arXiv-green)](https://arxiv.org/pdf/2004.12908.pdf)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "* In biological learning, the learning is lifelong, with agents conitnually building on past knowledge and experiences, improving on many tasks given data associated with any task. (e.g. learning a second language improves the individual's performance in his native language)\n",
    "* Even though classical ML can simultaneously optimize for multiple tasks, if is difficult to sequentially optimize for multiple tasks.\n",
    "* Catastrophic forgetting: performance on the prior tasks drop precipitously upon training on new tasks.\n",
    "* Biological learning doesn't suffer from catastrophic forgetting\n",
    "* Two camps of overcoming catastrophic forgetting:\n",
    "    * Fixed resources, and therefore, reallocate resources (compressing representations) to incorporate new knowledge (**biologically, this is adulthood**)\n",
    "    * Adds resources to incorporate new knowledge (**biologically, this is (juvenile) development**)\n",
    "* The inability to omnidirectionally transfer is one of the key liming factors of AI.\n",
    "* In ProgNN, new tasks yield additional representational capacity. ProgNN can transfer forward, but they cannot transfer backward.\n",
    "\n",
    "## Main Contributions\n",
    "\n",
    "* Representational ensembling that enables omnidirectional transfer via an \"Omni-voter\" layer\n",
    "* Computational time reduced from quadratic to quasilinear\n",
    "* Two types of omnidirectional learning algorithms: \n",
    "    * Omnidirectional Forests (ODIF)\n",
    "    * Omnidirectional Networks (ODIN)\n",
    "* ODIN and ODIF are resource building (juvenile) but since they can leverage prior representations, they can convert in to an resouce recruiting (adult) state too. \n",
    "\n",
    "## Background\n",
    "\n",
    "### Classical ML\n",
    "\n",
    "* Consider RVs $(X, Y) \\sim P_{X,Y}$ where $X \\sim \\mathcal{X}$ is the input and $Y \\sim \\mathcal{Y}$ is the label. \n",
    "* $P_{X,Y} \\in \\mathcal{P}_{X,Y}$ is the joint distribution of $(X, Y)$\n",
    "* Let $l \\colon \\mathcal{Y} \\times \\mathcal{Y} \\longrightarrow (0, \\infty]$ be a loss function\n",
    "* The goal of classifcal ML is to find the hypothesis (predictor/ decision rule) $h \\colon \\mathcal{X} \\longrightarrow \\mathcal{Y}$ that minimizes te expected loss or *risk*,\n",
    "    $$ R(h) = \\mathbb{E}_{X, Y}[l(h(X), Y)] $$\n",
    "* A learning algorithm is a function $f$ that maps a dataset $\\bf{S}_n = \\{ X_i, Y_i \\}_{i=1}^n$. \n",
    "* If $n$ samples of $(X, Y)$ is i.i.d from some true but unknown $P_{X,Y}$, the generalization error or expected risk is given by,\n",
    "    $$ \\mathbb{E}[R(f(\\bf{S}_n))]$$\n",
    "* The goal: choose a learner $f$ that learns a hypothesis $h$ that has a small generalization error for the given task.\n",
    "\n",
    "### Lifelong Learning (LL)\n",
    "\n",
    "* Lifelong learning generalizes classifcal ML in the following ways:\n",
    "    * environment of $\\mathcal{T}$ tasks instead of a single task\n",
    "    * data arrive sequentially, instead of batch mode\n",
    "    * computational complexity contraints on the learning algoritm and hypotheses\n",
    "* Goal of LL: given new data and a new task, use all the exisiting data to achieve a lower generalization error on the new task, while also using the new data to obtain a lower generalization error on the previous tasks.\n",
    "* previous work: \n",
    "    * updating a fixed parametric model as new tasks arrive\n",
    "    * adding resources as new tasks arrive\n",
    "    * store/ replay previously encountered data to reduce forgetting\n",
    "* Task-aware: the learner is aware of all-task details for all tasks $h \\colon \\mathcal{X} \\times \\mathcal{T} \\longrightarrow \\mathcal{Y}$.\n",
    "* Task-unaware (task-agnostic): learner may not know that the task has changed at all $h \\colon \\mathcal{X} \\longrightarrow \\mathcal{Y}$.\n",
    "\n",
    "### Reference Algorithms\n",
    "\n",
    "**Resource Building Algorithms**: Progressive Neural Nets (ProgNN), Deconvolution-Factorized CNNs (DF-CNNs)\n",
    "\n",
    "**Fixed Capacity Algorithms**: Elastic Weight Consolidation (EWC), Online-EWC (O-EWC), Synaptic Intelligence (SI), Learning without Forgetting (LwF), ‘None’ and two variants of exact replay (Total Replay and Partial Replay).\n",
    "\n",
    "## Evaluation Criteria\n",
    "\n",
    "### Transfer Efficiency\n",
    "\n",
    "$$ TE_n^t(f) = \\frac{\\mathbb{E}[R^t(f(S_n^t))]}{\\mathbb{E}[R^t(f(S_n))]} $$\n",
    "\n",
    "where, $t$ is the task with sample size $n$. \n",
    "\n",
    "* The algorithm $f$ has transfer learned iff $TE_n^t(f) > 1$\n",
    "\n",
    "* **Interpretation**: Transfer efficieny is the ratio of the generalization error of (i) an algorithm that has learnt only from data associated with a given task to (ii) the same learning algorithm that also has access to other data. \n",
    "\n",
    "### Forward Transfer Efficiency\n",
    "\n",
    "$$ FTE_n^t(f) = \\frac{\\mathbb{E}[R^t(f(S_n^t))]}{\\mathbb{E}[R^t(f(S_n^{<t}))]} $$\n",
    "\n",
    "* $FTE_n^t(f) > 1$ indicates that the algorithm has used data associated with past tasks to improve performance on task $t$. (forward transfers)\n",
    "\n",
    "* **Interpretation**: Forward transfer efficiency is the expected ratio of the risk of the learning algorithm with (i) access only to task $t$ data, (ii) to access to the data up to and inclduing the last observation from tast $t$.\n",
    "\n",
    "* Measures the relative effect of previously seen out-of-task data on the performance on task $t$.\n",
    "\n",
    "### Backward Transfer Efficiency \n",
    "\n",
    "$$ BTE_n^t(f) = \\frac{\\mathbb{E}[R^t(f(S_n^{<t}))]}{\\mathbb{E}[R^t(f(S_n))]} $$\n",
    "\n",
    "* $BTE_n^t(f) > 1$ indicates that the algorithm has used data associated with future tasks to improve performance on previous task $t$. (backward transfers)\n",
    "\n",
    "### Other \n",
    "\n",
    "* If we have a sequence in which tasks do not repeat, transfer efficiency for the first task is all backwards transfer, for the last task it is all forwards transfer, and for the middle tasks it is a combination of the two.\n",
    "\n",
    "* TE factorize in to FTE and BTE: $ TE_n^t(f) = FTE_n^t(f) \\times BTE_n^t(f) $\n",
    "\n",
    "## Omnidirectional Algorithms\n",
    "\n",
    "* Approach relies on hypotheses of the nature, $h( \\cdot ) = w \\odot v \\odot u ( \\cdot )$. \n",
    "* Representer ($u$): maps an $\\mathcal{X}$ valued input into an internal representation space $\\bar{ \\mathcal{X}}$. \n",
    "* Voter ($v$): maps transformed data into a posterior distribution on the response space. \n",
    "* Decider ($w$): produces a predicted label. \n",
    "* In a generalized format, each voter can be allowed to ensemble all the exisiting representations, regardless of the order in which they learnt. This done by the **Omni-voter layer**.\n",
    "* When the representers have learnt complementary properties, it could help the course of multi-task learning.\n",
    "* In ODIF: \n",
    "    * Representer: Decision forest (output: one-hot encoded vector representations)\n",
    "    * Voter: Populating the cells of the partitions and taking class votes with out-of-bag samples, as in ‘honest trees' (output: the posteriors)\n",
    "    * Decider: Average the posterior estimates (output: the argmax)\n",
    "* In ODIN: \n",
    "    * Representer: Backbone of a DN without the final layer\n",
    "    * Voter: learned via K-Nearest Neighbors\n",
    "    * Decider: Fully connected layer\n",
    "* In ODIF and ODIN both, \n",
    "    * A new representer is built, when new data from a new task arrive.\n",
    "    * Then a voter is built which integrates information from the existing representers. (enables forward transfer)\n",
    "    * When new data of an old task arrives, the voters are updated from the new representations. (enables backward transfer)\n",
    "    * New test data are passed through all the exisiting representers and corresponding voters to make a prediction\n",
    "    * When updating the previous task voters with the cross task posteriors, we do not need to subsample the previous task data.\n",
    "* In ODIN: \n",
    "    * Exclues lateral connections unlike ProgNN\n",
    "    * Representations are independent avoiding intereference between representations\n",
    "\n",
    "## Experiments\n",
    "\n",
    "Check the manuscript.\n",
    "\n",
    "## Results\n",
    "\n",
    "* The following have been studied. \n",
    "    * computational space and time complexity of internal representations\n",
    "    * representational capacity \n",
    "* Types of lifelong learning algorithms based on the computational taxonomy.\n",
    "    * parametric: \n",
    "        * algorithms with fixed resources\n",
    "        * eventually all algorithms will catastrophically forget at least some knowledge\n",
    "        * EWC, SI, LwF\n",
    "    * semi-parametric\n",
    "        * algorithms whose representational capacity grows slower than sample size\n",
    "        * have fixed representational capacity per task\n",
    "        * ProgNN, DF-CNN\n",
    "        * may lack representation capacity to perform well on complex tasks\n",
    "        * may waster resources on simpler tasks\n",
    "    * nonparametric\n",
    "        * ODIF is the only nonparametric method up to this day\n",
    "\n",
    "## Summary\n",
    "\n",
    "* Quasilinar representational ensembling as an approach to omnidirectional lifelong learning\n",
    "\n",
    "* This representation ensembling approach closely resembles the contructivist view of brain development\n",
    "\n",
    "* Forest-based representation ensembling approaches can easily add new resources when appropriate.\n",
    "\n",
    "* The concept of omnidirectional transfer of knowledge is proposed to overcome the issue of catastrophic forgetting. \n",
    "\n",
    "* Through omnidirectional transfer, it is possible to realize the goal of lifelong learning, which is to improve the performance on a new task using knowledge about existing tasks and their data, while improving the performance on the previous tasks using the knowledge about new tasks and their data. \n",
    "\n",
    "* This work further uses progressive learning concepts to incorporate resource building and resource recruitment into the proposed algorithms. \n",
    "\n",
    "## Potential Future directions? \n",
    "\n",
    "* How can we expand the proposed learning framework into task-agnostic situations? \n",
    "* How can we make deep learning to enable dynamically adding resources when appropriate?\n",
    "* Obviate the need to store all the data by using a generative model?\n",
    "* Paradigm of ensembling representations rather than learners can be readily applied more generally. (e.g. batch effects, federated learning)\n",
    "* Substantial pruning during development and maturity in the brain circuitry is important for performance. This motivates future work for pruning adversarial representers to enhance the transferabilty among tasks even more.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}