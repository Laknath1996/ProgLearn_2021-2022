# Notes from 9/28/21, Jayanta presentation 
## What is a learning task?

![image](https://user-images.githubusercontent.com/89429238/135137797-e5409634-e786-416f-b229-9d6f72ef39e7.png)

- if any of these componenets change, then the task changes
- A shift in the task is a change in any one of these components

## What is unsupervised learning?
- when you are not given class labels

## What is forward learning?

## What is backward learning?

## What happens when you multiply forward and backward learning?
- you get transfer learning

## Simple example where we can do lifelong learning
![image](https://user-images.githubusercontent.com/89429238/135138623-fcd49218-e447-4260-85cb-531030ab3f96.png)

- model gn trained on data Dn, no reg = not constraining params to be something 
- Minimizes R, risk
- Generalization error is the expected risk
- train and test set should be independent of each other
- fixed cap = when you get more data you arent changing the size of the model
- new task data comes in so we need to retrain model gn

What do we need to consider now?
- similarity between the two tasks 
- gen error on the prev and current task

What will happen with your model when you feed it data with slightly shifted data (so they have slight over lap)?
- it will perform slightly better on the new task, gen error improves

How can we mitigate forgetting?
- use capacity efficiently, regularize the params (EWC, SI) <- this paper explains formula 

![image](https://user-images.githubusercontent.com/89429238/135140293-fb44be15-4233-444b-9513-d02e640552b2.png)

This method somewhat mitigates forgetting but not that much

- replay exact or similar represenations (inexact) of t he old task (LwF) (learning without forgetting algo)

![image](https://user-images.githubusercontent.com/89429238/135140493-d99643ad-011d-43ed-a13e-37cad9b3ccec.png)

- after intro replay, this is what our loss function looks like ^
- this is kinda like when we dream, revising what we have done 
- but if you have fixed cap, you will eventually forget after enough tasks

Maybe we can find a way to summarize what we learned before so it takes up less space?

What else can we do to mitigate forgetting?
- concat all the task data and train a model with increase cap per task : called sequential multitask learning
- learn one representation per task without any interaction between them (this should be little easier)
- ^ since there is no interaction, no FL or BL so you have TL 1

- so we want to let representers interact with each other to get more BLE, FLE
- progressive neural network learns lateral connections from the old task representers to the current task

![image](https://user-images.githubusercontent.com/89429238/135142062-f40cf74c-c5e5-4c9a-94da-fb38a078c09a.png)
- this progressive neural net has no backward transfer
- in this case we are learning task 3
- only learning the lateral connections here and modifying the boxes 
- whenever we intro a task we can do FT

## Our approach
![image](https://user-images.githubusercontent.com/89429238/135142539-731115c6-d8af-4dea-b58d-00e6de1abad8.png)

- using training data to learn voters creates bias 
- using a holdout data set to learn voteres eliminates that 
- How do we do a prediction in C?
- each representer is learned independently, they can only interact with each other in the voter layer, each voter is retrained for each new task
- voters learn from every task but representer only learns from the task it was trained on 
- 
