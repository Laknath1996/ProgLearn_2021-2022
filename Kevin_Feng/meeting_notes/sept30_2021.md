# 9/28/21
What should we have by tuesday? (10/5/21)
- pick an issue to discuss for tuesday

Why are simulation studies important?

What is the no free lunch theorem?
- if you are smart enough you can break any model

Notes on lecture:
- The more overlap there is in a distribution, the more complicated it is
- ie the Gaussian xor, if the two colors had more overlap

What is Gaussian xnor?
- rotate xor points by 90 degrees

what is Gaussian rxor?
- rotate points by 45 degrees, non axis aligned

Lifelong learning is meant for small sample size
- if you have large sample size, you dont need transfer learning
- TL is more useful when you have a limited amount of data, you want to see how much you can benefit from other data

When is ODIF better than RF?
- When you introduce a new task

How is transfer learning effected by sample size?
- you will transfer less if you have enough samples

What is CIFAR and its relation to proglearn?
- CIFAR is a image classification dataset with 100 classes of images
- 500 training images and 100 testing images per class
- all images 32x32 color images
- CIFAR 10x10 breaks the 100-class task problem into 10 tasks, each with 10-class

![image](https://user-images.githubusercontent.com/89429238/135508595-4ab905fa-8b24-4078-a0e9-9e2a5ba2b89a.png)

- in proglearn, they merged the 500 and 100 training and test set and randomly subsampled to train

What do you each of the 6 plots presented in the paper mean? (the complicated looking ones)
In the bottom 3 plots, they changed their definition a little bit (resource contrained)
- artificially made transfer formulas have same amount of trees on the bottom and top of equation

**Skim through the paper again**
