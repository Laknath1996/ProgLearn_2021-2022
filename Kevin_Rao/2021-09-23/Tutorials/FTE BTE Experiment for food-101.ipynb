{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c842d33b",
   "metadata": {},
   "source": [
    "# FTE/BTE Experiment for food-101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7806c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc15e7",
   "metadata": {},
   "source": [
    "Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1205bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data_dir = \"food-101/images/\" # replace with the path name for wherever the downloaded food-101 images have been stored\n",
    "foods_sorted = sorted(os.listdir(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "178e856a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 308 and the array at index 1 has size 512",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KEVINR~1\\AppData\\Local\\Temp/ipykernel_57292/1623653161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mdata_xk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_xk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoods_sorted\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfood_class\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Add to the initialized data_x* array until it contains all images from the 10 classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 2, the array at index 0 has size 308 and the array at index 1 has size 512"
     ]
    }
   ],
   "source": [
    "dict_x = {}\n",
    "for k in range(10):\n",
    "    # Initialize data_x* with the first image in the first class, then concatenate to acquire all images from the first class\n",
    "    food_class = os.listdir(os.path.join(data_dir,foods_sorted[10*k]))\n",
    "    data_xk = [plt.imread(os.path.join(data_dir, foods_sorted[10*k], food_class[0]))]\n",
    "\n",
    "    for i in range(1,1000):\n",
    "            data_xk = np.concatenate([data_xk, [(plt.imread(os.path.join(data_dir, foods_sorted[10*k], food_class[i])))]],axis=1)\n",
    "\n",
    "    # Add to the initialized data_x* array until it contains all images from the 10 classes\n",
    "    # Concatenating more than 10000 images per batch increases the run time by a lot\n",
    "    for j in range(((k*10)+1),(10*(k+1))):\n",
    "        food_class = os.listdir(os.path.join(data_dir,foods_sorted[j]))\n",
    "        for i in range(0,1000):\n",
    "            data_xk = np.c_([data_xk, [(plt.imread(os.path.join(data_dir, foods_sorted[j], food_class[i])))]])\n",
    "\n",
    "    dict_x['data_x' + str(k+1)] = data_xk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b6f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine individual numpy arrays for x data for each batch of 10 classes all into one big numpy array\n",
    "data_x = np.concatenate([dict_x['data_x1'], dict_x['data_x2'], dict_x['data_x3']])\n",
    "data_x = np.concatenate([data_x, dict_x['data_x4'], dict_x['data_x5']])\n",
    "data_x = np.concatenate([data_x, dict_x['data_x6'], dict_x['data_x7']])\n",
    "data_x = np.concatenate([data_x, dict_x['data_x8'], dict_x['data_x9']])\n",
    "data_x = np.concatenate([data_x, dict_x['data_x10']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d6b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create y data containing 100 class labels\n",
    "data_y = np.full((1000), 0, dtype=int)\n",
    "for i in range(1,100):\n",
    "    data_y = np.concatenate([data_y, np.full((1000), i, dtype=int)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.fte_bte_food101_functions import run_fte_bte_exp\n",
    "\n",
    "fte = []\n",
    "bte = []\n",
    "te = []\n",
    "accuracies = []\n",
    "\n",
    "for which_task in range(1,11):\n",
    "\n",
    "    def run_parallel_exp(shift):\n",
    "\n",
    "        df_list = run_fte_bte_exp(data_x, data_y, which_task, shift = shift)\n",
    "\n",
    "        return df_list\n",
    "\n",
    "    shifts = np.arange(0,10,1)\n",
    "    acc = []\n",
    "\n",
    "    with Pool(8) as p:\n",
    "        # Paralell processing to run the experiment using a different batch for the test set each time\n",
    "        acc.append(\n",
    "            p.map(run_parallel_exp, shifts)\n",
    "        )\n",
    "\n",
    "    # Average forward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range(which_task):\n",
    "        for y in range(10):\n",
    "            for x in range(10):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "\n",
    "    # Calculate and store FTE\n",
    "    fte.append((1-acc_z[0])/(1-acc_z[-1]))\n",
    "\n",
    "    # Average backward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range((which_task - 1), 10):\n",
    "        for y in range(10):\n",
    "            for x in range(10):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "\n",
    "    # Calculate and store accuracies, BTE, and TE\n",
    "    accuracies.append(acc_z)\n",
    "    calc_bte = (1-acc_z[0])/([1-a for a in acc_z])\n",
    "    bte.append(calc_bte)\n",
    "    te.append([fte[(which_task-1)]*a for a in calc_bte])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceeee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.fte_bte_food101_functions import run_fte_bte_exp\n",
    "\n",
    "fte = []\n",
    "bte = []\n",
    "te = []\n",
    "accuracies = []\n",
    "\n",
    "for which_task in range(1,11):\n",
    "\n",
    "    def run_parallel_exp(shift):\n",
    "\n",
    "        df_list = run_fte_bte_exp(data_x, data_y, which_task, shift = shift)\n",
    "\n",
    "        return df_list\n",
    "\n",
    "    shifts = np.arange(0,10,1)\n",
    "    acc = []\n",
    "\n",
    "    with Pool(8) as p:\n",
    "        # Paralell processing to run the experiment using a different batch for the test set each time\n",
    "        acc.append(\n",
    "            p.map(run_parallel_exp, shifts)\n",
    "        )\n",
    "\n",
    "    # Average forward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range(which_task):\n",
    "        for y in range(10):\n",
    "            for x in range(10):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "\n",
    "    # Calculate and store FTE\n",
    "    fte.append((1-acc_z[0])/(1-acc_z[-1]))\n",
    "\n",
    "    # Average backward transfer accuracies accross all permutations of testing and training batches for each task\n",
    "    acc_x = []\n",
    "    acc_y = []\n",
    "    acc_z = []\n",
    "    for z in range((which_task - 1), 10):\n",
    "        for y in range(10):\n",
    "            for x in range(10):\n",
    "                acc_x.append(acc[0][x][y]['task_accuracy'][z])\n",
    "            acc_y.append(np.mean(acc_x))\n",
    "            acc_x = []\n",
    "        acc_z.append(np.mean(acc_y))\n",
    "        acc_y = []\n",
    "\n",
    "    # Calculate and store accuracies, BTE, and TE\n",
    "    accuracies.append(acc_z)\n",
    "    calc_bte = (1-acc_z[0])/([1-a for a in acc_z])\n",
    "    bte.append(calc_bte)\n",
    "    te.append([fte[(which_task-1)]*a for a in calc_bte])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
