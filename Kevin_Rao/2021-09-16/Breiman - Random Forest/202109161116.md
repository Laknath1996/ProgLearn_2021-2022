---
alias:
---
# Random forest performance is resistant to noise in training data.
## Metadata
- ID: 202109161116
- Date Created: [[2021-09-16]]
- Status: #status/in_progress
- Note Type: #note/permenant_note
- Topic: [[Random Forest]], [[Machine Learning]], [[Adaboost]]
- Tags: 
---

Dietterich (1998) demonstrated that when training set is randomly altered, accuracy of Adaboost degenerates while bagging and random split were more resistant to the noise. [[Leo Breiman]] conducted an experiment injecting noise into the training data by altering 5% of the labels into a different class label selected uniformly from possible labels. 10% of the data was used as a test set. This was done 50 times for Adaboost, forest with random input, and forest with linear inputs. 

Adaboost had significantly greater error rate when classifying data with noise than without while the forest classifiers had a less increase in error rates. The increase in error rate for Adaboost was also data dependent. This may be a result of Adaboost iteratively altering weights of instances of misclassified data points which persist, resulting in warped weight values. Random forest by contrast does not focus on the weights of subset of instances, reducing effect of noise.

> ![[Breiman - Random Forest#^3067b5]]
---
## Source
[[Breiman - Random Forest|Random Forest]]